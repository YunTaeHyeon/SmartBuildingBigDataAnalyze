{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35685f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.0.1-cp39-cp39-win_amd64.whl (172.4 MB)\n",
      "     -------------------------------------- 172.4/172.4 MB 5.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: networkx in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\dongh\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25fad989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 regdate  temp  humi    co2  dust_pm1  dust_pm_25  dust_pm_10  \\\n",
      "0        2023-01-01 0:00  21.2  34.0  414.0      14.0        14.0        14.0   \n",
      "1        2023-01-01 0:01  21.2  34.0  411.0      13.0        13.0        13.0   \n",
      "2        2023-01-01 0:02  21.2  34.0  409.0      14.0        14.0        14.0   \n",
      "3        2023-01-01 0:03  21.2  34.0  409.0      14.0        14.0        14.0   \n",
      "4        2023-01-01 0:04  21.2  34.0  415.0      14.0        14.0        14.0   \n",
      "...                  ...   ...   ...    ...       ...         ...         ...   \n",
      "388795  2023-01-27 23:55  17.4  17.0  414.0       9.0         9.0         9.0   \n",
      "388796  2023-01-27 23:56  17.4  17.0  410.0       9.0         9.0         9.0   \n",
      "388797  2023-01-27 23:57  17.4  17.0  417.0       9.0         9.0         9.0   \n",
      "388798  2023-01-27 23:58  17.5  17.0  414.0       9.0         9.0         9.0   \n",
      "388799  2023-01-27 23:59  17.4  17.0  415.0       9.0         9.0         9.0   \n",
      "\n",
      "        illuminance     voc    eco2  PIR  Àç½ÇÀÎ¿ø  \n",
      "0               0.0  2535.0  2845.0  0.0         1  \n",
      "1               0.0  2535.0  2845.0  0.0         1  \n",
      "2               0.0  2535.0  2845.0  0.0         1  \n",
      "3               0.0  2500.0  2829.0  0.0         1  \n",
      "4               0.0  2500.0  2829.0  0.0         1  \n",
      "...             ...     ...     ...  ...       ...  \n",
      "388795          1.0     7.0   452.0  0.0         0  \n",
      "388796          1.0     7.0   452.0  0.0         0  \n",
      "388797          1.0     7.0   452.0  0.0         0  \n",
      "388798          1.0     8.0   455.0  0.0         0  \n",
      "388799          1.0     7.0   452.0  0.0         0  \n",
      "\n",
      "[388800 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "da1 = pd.read_csv(\"/Users/dongh/competition DATA/train_data.csv\", encoding='cp1252')\n",
    "\n",
    "print(da1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a8cd62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 regdate  temp  humi    co2  dust_pm1  dust_pm_25  dust_pm_10  \\\n",
      "0       2023-01-01 11:03  20.1  31.0  570.0      20.0        20.0        20.0   \n",
      "1       2023-01-01 11:06  20.1  31.0  577.0      20.0        20.0        20.0   \n",
      "2       2023-01-01 11:07  20.1  31.0  577.0      20.0        20.0        20.0   \n",
      "3       2023-01-01 11:09  20.1  31.0  570.0      20.0        20.0        20.0   \n",
      "4       2023-01-01 11:11  20.1  31.0  567.0      20.0        20.0        20.0   \n",
      "...                  ...   ...   ...    ...       ...         ...         ...   \n",
      "279973  2023-01-27 23:55  17.4  17.0  414.0       9.0         9.0         9.0   \n",
      "279974  2023-01-27 23:56  17.4  17.0  410.0       9.0         9.0         9.0   \n",
      "279975  2023-01-27 23:57  17.4  17.0  417.0       9.0         9.0         9.0   \n",
      "279976  2023-01-27 23:58  17.5  17.0  414.0       9.0         9.0         9.0   \n",
      "279977  2023-01-27 23:59  17.4  17.0  415.0       9.0         9.0         9.0   \n",
      "\n",
      "        illuminance  voc   eco2  PIR  person  \n",
      "0               1.0  1.0  411.0  0.0       2  \n",
      "1               1.0  2.0  416.0  0.0       2  \n",
      "2               1.0  2.0  416.0  0.0       2  \n",
      "3               1.0  2.0  416.0  0.0       2  \n",
      "4               1.0  1.0  409.0  0.0       2  \n",
      "...             ...  ...    ...  ...     ...  \n",
      "279973          1.0  7.0  452.0  0.0       0  \n",
      "279974          1.0  7.0  452.0  0.0       0  \n",
      "279975          1.0  7.0  452.0  0.0       0  \n",
      "279976          1.0  8.0  455.0  0.0       0  \n",
      "279977          1.0  7.0  452.0  0.0       0  \n",
      "\n",
      "[279978 rows x 12 columns]\n",
      "                regdate   temp  humi    co2  dust_pm1  dust_pm_25  dust_pm_10  \\\n",
      "0      2023-02-01 13:47   19.4  31.0  422.0      12.0        12.0        12.0   \n",
      "1      2023-02-01 13:48   19.4  31.0  418.0      12.0        12.0        12.0   \n",
      "2      2023-02-01 13:49   19.4  31.0  419.0      12.0        12.0        12.0   \n",
      "3      2023-02-01 13:50   19.4  31.0  433.0      12.0        12.0        12.0   \n",
      "4      2023-02-01 13:51   19.4  31.0  434.0      13.0        13.0        13.0   \n",
      "...                 ...    ...   ...    ...       ...         ...         ...   \n",
      "84995  2023-02-07 11:22  107.3   0.0  462.0      24.0        24.0        24.0   \n",
      "84996  2023-02-07 11:23  107.3   0.0  462.0      25.0        25.0        25.0   \n",
      "84997  2023-02-07 11:24  107.3   0.0  467.0      24.0        24.0        24.0   \n",
      "84998  2023-02-07 11:25  -29.7   0.0  466.0      25.0        25.0        25.0   \n",
      "84999  2023-02-07 11:26  107.3   0.0  476.0      26.0        26.0        26.0   \n",
      "\n",
      "       illuminance   voc   eco2  PIR  person  \n",
      "0              2.0   9.0  463.0  0.0       0  \n",
      "1              3.0  11.0  473.0  0.0       0  \n",
      "2              4.0   9.0  461.0  1.0       0  \n",
      "3              5.0  11.0  473.0  0.0       0  \n",
      "4              5.0  11.0  473.0  0.0       0  \n",
      "...            ...   ...    ...  ...     ...  \n",
      "84995          8.0  20.0  534.0  0.0       0  \n",
      "84996          8.0  20.0  534.0  0.0       0  \n",
      "84997          8.0  20.0  534.0  0.0       0  \n",
      "84998          8.0  20.0  534.0  0.0       0  \n",
      "84999          8.0  20.0  534.0  0.0       0  \n",
      "\n",
      "[85000 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "da = pd.read_csv('/Users/dongh/competition DATA/train_data.csv', encoding='cp1252')\n",
    "\n",
    "data = da.rename(columns={'Àç½ÇÀÎ¿ø': 'person'})\n",
    "\n",
    "# 이상치 식별 및 제거\n",
    "for column in data.columns[1:]:\n",
    "    q1 = data[column].quantile(0.25)\n",
    "    q3 = data[column].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_fence = q1 - 1.5 * iqr\n",
    "    upper_fence = q3 + 1.5 * iqr\n",
    "\n",
    "    outliers = (data[column] < lower_fence) | (data[column] > upper_fence)\n",
    "    data = data[~outliers]\n",
    "\n",
    "# 인덱스 재설정\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# 수정된 데이터 저장\n",
    "save_path = '/Users/dongh/competition DATA/modified_train_data.csv'\n",
    "data.to_csv(save_path, index=False)\n",
    "\n",
    "print(data)\n",
    "\n",
    "df_test = pd.read_csv(\"/Users/dongh/competition DATA/test_data.csv\", encoding='ISO-8859-1')\n",
    "\n",
    "data1 = df_test.rename(columns={'Àç½ÇÀÎ¿ø': 'person'})\n",
    "# 수정된 데이터 저장\n",
    "save_path = '/Users/dongh/competition DATA/modified_test_data.csv'\n",
    "data1.to_csv(save_path, index=False)\n",
    "print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89839586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([201920, 1, 28, 28])\n",
      "torch.Size([84920, 1, 28, 28])\n",
      "Epoch [1/10], Loss: 2.2042932510375977, Accuracy: 0.3996231747527084\n",
      "Epoch [2/10], Loss: 1.6127078533172607, Accuracy: 0.45370937352802637\n",
      "Epoch [3/10], Loss: 1.5080968141555786, Accuracy: 0.4652614225153085\n",
      "Epoch [4/10], Loss: 1.4698766469955444, Accuracy: 0.47204427696655676\n",
      "Epoch [5/10], Loss: 1.4455180168151855, Accuracy: 0.4738577484691474\n",
      "Epoch [6/10], Loss: 1.426044225692749, Accuracy: 0.4744112105511069\n",
      "Epoch [7/10], Loss: 1.4092475175857544, Accuracy: 0.4771902967498822\n",
      "Epoch [8/10], Loss: 1.3943136930465698, Accuracy: 0.4773551577955723\n",
      "Epoch [9/10], Loss: 1.3810144662857056, Accuracy: 0.47740226095148375\n",
      "Epoch [10/10], Loss: 1.3692582845687866, Accuracy: 0.47747291568535094\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import gensim\n",
    "from sklearn.preprocessing import normalize\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def pre_df(df):\n",
    "    df = df.dropna()\n",
    "    label = df['person']\n",
    "    df = df.drop('person', axis=1)\n",
    "    df = df.drop('regdate', axis=1)\n",
    "    df = df.drop('PIR', axis=1)\n",
    "    df_33 = df.values.reshape(-1,3,3)\n",
    "    return df_33, label\n",
    "#0~255 스케일링 함수\n",
    "def scale_255(array,i,j):\n",
    "    # i,j 위치의 요소들을 추출하여 배열 생성\n",
    "    first_elements = array[:, i, j]\n",
    "    # 첫 번째 요소들의 최솟값과 최댓값 계산\n",
    "    min_value = np.min(first_elements)\n",
    "    max_value = np.max(first_elements)\n",
    "    # 스케일링 수행\n",
    "    scaled_array = (first_elements - min_value) * (255 / (max_value - min_value))\n",
    "    return scaled_array\n",
    "def make_28(df_33):\n",
    "    # 결과 행렬을 저장할 빈 배열 생성\n",
    "    expanded_data = np.zeros((len(df_33), 28, 28))\n",
    "    # df_33의 각 3x3 배열에 대해 반복\n",
    "    for idx, arr in enumerate(df_33):\n",
    "        expanded_arr = np.repeat(arr,9,axis=0)\n",
    "        expanded_arr = np.repeat(expanded_arr,9,axis=1)\n",
    "        # 패딩을 추가한 새로운 28x28 배열 생성\n",
    "        expanded_arr = np.pad(expanded_arr, ((0, 1), (0, 1)), mode='constant')\n",
    "        expanded_data[idx] = expanded_arr\n",
    "    return expanded_data\n",
    "\n",
    "df = pd.read_csv(\"/Users/dongh/competition DATA/modified_train_data.csv\", encoding='ISO-8859-1')\n",
    "df_33, label = pre_df(df)\n",
    "#스케일링 함수 전체 적용\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        df_33[:,i,j] = scale_255(df_33,i,j)\n",
    "df_33 = make_28(df_33)\n",
    "# 배열을 PyTorch Tensor로 변환\n",
    "input_data = torch.from_numpy(df_33).unsqueeze(1).float()  # 차원 수정\n",
    "# 라벨 데이터를 PyTorch Tensor로 변환\n",
    "target = torch.tensor(label.values)\n",
    "print(input_data.shape)\n",
    "#test\n",
    "df_test = pd.read_csv(\"/Users/dongh/competition DATA/modified_test_data.csv\", encoding='ISO-8859-1')\n",
    "df_test_33, label_test = pre_df(df_test)\n",
    "#스케일링 함수 전체 적용\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        df_test_33[:,i,j] = scale_255(df_test_33,i,j)\n",
    "df_test_33 = make_28(df_test_33)\n",
    "# 배열을 PyTorch Tensor로 변환\n",
    "input_test = torch.from_numpy(df_test_33).unsqueeze(1).float()  # 차원 수정\n",
    "# 라벨 데이터를 PyTorch Tensor로 변환\n",
    "target_test = torch.tensor(label_test.values)\n",
    "print(input_test.shape)\n",
    "\n",
    "# LeNet-5 모델 정의 (시퀀셜)\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 5 * 5, 400),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(400, 120),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(120, 7)\n",
    ")\n",
    "\n",
    "# 모델 학습 또는 예측 수행\n",
    "\n",
    "# 손실 함수와 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# 학습\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # 입력 데이터의 forward pass\n",
    "    outputs = model(input_data)\n",
    "\n",
    "    # 손실 계산\n",
    "    loss = criterion(outputs, target)\n",
    "\n",
    "    # 역전파 및 가중치 업데이트\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 예측\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    # 예측 결과와 실제 라벨 비교하여 정확도 계산\n",
    "    accuracy = (predicted == target_test).sum().item() / target_test.size(0)\n",
    "\n",
    "    # 현재 에폭의 손실과 정확도 출력\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}, Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778aefbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
