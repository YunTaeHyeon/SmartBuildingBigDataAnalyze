{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35685f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fad989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "da1 = pd.read_csv(\"/Users/dongh/competition DATA/train_data.csv\", encoding='cp1252')\n",
    "\n",
    "print(da1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8cd62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = pd.read_csv('/Users/dongh/competition DATA/train_data.csv', encoding='cp1252')\n",
    "\n",
    "data = da.rename(columns={'Àç½ÇÀÎ¿ø': 'person'})\n",
    "\n",
    "# 이상치 식별 및 제거\n",
    "for column in data.columns[1:]:\n",
    "    q1 = data[column].quantile(0.25)\n",
    "    q3 = data[column].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_fence = q1 - 1.5 * iqr\n",
    "    upper_fence = q3 + 1.5 * iqr\n",
    "\n",
    "    outliers = (data[column] < lower_fence) | (data[column] > upper_fence)\n",
    "    data = data[~outliers]\n",
    "\n",
    "# 인덱스 재설정\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# 수정된 데이터 저장\n",
    "save_path = '/Users/dongh/competition DATA/modified_train_data.csv'\n",
    "data.to_csv(save_path, index=False)\n",
    "\n",
    "print(data)\n",
    "\n",
    "df_test = pd.read_csv(\"/Users/dongh/competition DATA/test_data.csv\", encoding='ISO-8859-1')\n",
    "\n",
    "data1 = df_test.rename(columns={'Àç½ÇÀÎ¿ø': 'person'})\n",
    "# 수정된 데이터 저장\n",
    "save_path = '/Users/dongh/competition DATA/modified_test_data.csv'\n",
    "data1.to_csv(save_path, index=False)\n",
    "print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3094e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_test = pd.read_csv(\"/Users/dongh/competition DATA/test_data.csv\", encoding='ISO-8859-1')\n",
    "\n",
    "data = df_test.rename(columns={'Àç½ÇÀÎ¿ø': 'person'})\n",
    "\n",
    "# 이상치 식별 및 제거\n",
    "for column in data.columns[1:]:\n",
    "    q1 = data[column].quantile(0.25)\n",
    "    q3 = data[column].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_fence = q1 - 1.5 * iqr\n",
    "    upper_fence = q3 + 1.5 * iqr\n",
    "\n",
    "    outliers = (data[column] < lower_fence) | (data[column] > upper_fence)\n",
    "    data = data[~outliers]\n",
    "\n",
    "# 인덱스 재설정\n",
    "data = data.reset_index(drop=True)    \n",
    "    \n",
    "# 수정된 데이터 저장\n",
    "save_path = '/Users/dongh/competition DATA/modified_test_data.csv'\n",
    "data.to_csv(save_path, index=False)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89839586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([201920, 1, 28, 28])\n",
      "torch.Size([43547, 1, 28, 28])\n",
      "Epoch [1/20], Loss: 2.6241281032562256, Accuracy: 0.49849587801685535\n",
      "Epoch [2/20], Loss: 2.960460901260376, Accuracy: 0.49799067674007397\n",
      "Epoch [3/20], Loss: 2.1471338272094727, Accuracy: 0.34209015546421107\n",
      "Epoch [4/20], Loss: 1.8008848428726196, Accuracy: 0.5700737134590212\n",
      "Epoch [5/20], Loss: 1.6957495212554932, Accuracy: 0.546903345810274\n",
      "Epoch [6/20], Loss: 1.6001832485198975, Accuracy: 0.5102762532436218\n",
      "Epoch [7/20], Loss: 1.5247633457183838, Accuracy: 0.507933956414908\n",
      "Epoch [8/20], Loss: 1.4820704460144043, Accuracy: 0.5194617310032839\n",
      "Epoch [9/20], Loss: 1.4506399631500244, Accuracy: 0.5335384756699658\n",
      "Epoch [10/20], Loss: 1.4219902753829956, Accuracy: 0.544239557259972\n",
      "Epoch [11/20], Loss: 1.3949236869812012, Accuracy: 0.5542976554068019\n",
      "Epoch [12/20], Loss: 1.370550274848938, Accuracy: 0.5806370128826326\n",
      "Epoch [13/20], Loss: 1.3467540740966797, Accuracy: 0.595816014880474\n",
      "Epoch [14/20], Loss: 1.324641466140747, Accuracy: 0.6255539991273796\n",
      "Epoch [15/20], Loss: 1.3046305179595947, Accuracy: 0.6314786322823616\n",
      "Epoch [16/20], Loss: 1.2855453491210938, Accuracy: 0.655544584012676\n",
      "Epoch [17/20], Loss: 1.2690919637680054, Accuracy: 0.6499873699680805\n",
      "Epoch [18/20], Loss: 1.253531575202942, Accuracy: 0.6831239809860611\n",
      "Epoch [19/20], Loss: 1.2420262098312378, Accuracy: 0.6069763703584633\n",
      "Epoch [20/20], Loss: 1.2431098222732544, Accuracy: 0.7682733598181275\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import gensim\n",
    "from sklearn.preprocessing import normalize\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def pre_df(df):\n",
    "    df = df.dropna()\n",
    "    label = df['person']\n",
    "    df = df.drop('person', axis=1)\n",
    "    df = df.drop('regdate', axis=1)\n",
    "    df = df.drop('PIR', axis=1)\n",
    "    df_33 = df.values.reshape(-1,3,3)\n",
    "    return df_33, label\n",
    "#0~255 스케일링 함수\n",
    "def scale_255(array,i,j):\n",
    "    # i,j 위치의 요소들을 추출하여 배열 생성\n",
    "    first_elements = array[:, i, j]\n",
    "    # 첫 번째 요소들의 최솟값과 최댓값 계산\n",
    "    min_value = np.min(first_elements)\n",
    "    max_value = np.max(first_elements)\n",
    "    # 스케일링 수행\n",
    "    scaled_array = (first_elements - min_value) * (255 / (max_value - min_value))\n",
    "    return scaled_array\n",
    "def make_28(df_33):\n",
    "    # 결과 행렬을 저장할 빈 배열 생성\n",
    "    expanded_data = np.zeros((len(df_33), 28, 28))\n",
    "    # df_33의 각 3x3 배열에 대해 반복\n",
    "    for idx, arr in enumerate(df_33):\n",
    "        expanded_arr = np.repeat(arr,9,axis=0)\n",
    "        expanded_arr = np.repeat(expanded_arr,9,axis=1)\n",
    "        # 패딩을 추가한 새로운 28x28 배열 생성\n",
    "        expanded_arr = np.pad(expanded_arr, ((0, 1), (0, 1)), mode='constant')\n",
    "        expanded_data[idx] = expanded_arr\n",
    "    return expanded_data\n",
    "\n",
    "df = pd.read_csv(\"/Users/dongh/competition DATA/modified_train_data.csv\", encoding='ISO-8859-1')\n",
    "df_33, label = pre_df(df)\n",
    "#스케일링 함수 전체 적용\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        df_33[:,i,j] = scale_255(df_33,i,j)\n",
    "df_33 = make_28(df_33)\n",
    "# 배열을 PyTorch Tensor로 변환\n",
    "input_data = torch.from_numpy(df_33).unsqueeze(1).float()  # 차원 수정\n",
    "# 라벨 데이터를 PyTorch Tensor로 변환\n",
    "target = torch.tensor(label.values)\n",
    "print(input_data.shape)\n",
    "#test\n",
    "df_test = pd.read_csv(\"/Users/dongh/competition DATA/modified_test_data.csv\", encoding='ISO-8859-1')\n",
    "df_test_33, label_test = pre_df(df_test)\n",
    "#스케일링 함수 전체 적용\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        df_test_33[:,i,j] = scale_255(df_test_33,i,j)\n",
    "df_test_33 = make_28(df_test_33)\n",
    "# 배열을 PyTorch Tensor로 변환\n",
    "input_test = torch.from_numpy(df_test_33).unsqueeze(1).float()  # 차원 수정\n",
    "# 라벨 데이터를 PyTorch Tensor로 변환\n",
    "target_test = torch.tensor(label_test.values)\n",
    "print(input_test.shape)\n",
    "\n",
    "# LeNet-5 모델 정의 (시퀀셜)\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 5 * 5, 400),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(400, 120),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(120, 7)\n",
    ")\n",
    "\n",
    "# 모델 학습 또는 예측 수행\n",
    "\n",
    "# 손실 함수와 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 학습\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    # 입력 데이터의 forward pass\n",
    "    outputs = model(input_data)\n",
    "\n",
    "    # 손실 계산\n",
    "    loss = criterion(outputs, target)\n",
    "\n",
    "    # 역전파 및 가중치 업데이트\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 예측\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    # 예측 결과와 실제 라벨 비교하여 정확도 계산\n",
    "    accuracy = (predicted == target_test).sum().item() / target_test.size(0)\n",
    "\n",
    "    # 현재 에폭의 손실과 정확도 출력\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}, Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778aefbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
