{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35685f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89839586",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22088\\2131539302.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mdf_33\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscale_255\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_33\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[0mdf_33\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_28\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_33\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22088\\2131539302.py\u001b[0m in \u001b[0;36mscale_255\u001b[1;34m(array, i, j)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mscale_255\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m# i,j 위치의 요소들을 추출하여 배열 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mfirst_elements\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[1;31m# 첫 번째 요소들의 최솟값과 최댓값 계산\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mmin_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_elements\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 1 with size 2"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import gensim\n",
    "from sklearn.preprocessing import normalize\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def pre_df(df):\n",
    "    df = df.dropna()\n",
    "    label = df['person']\n",
    "    df = df.drop('person', axis=1)\n",
    "    df = df.drop('regdate', axis=1)\n",
    "    df = df.drop('PIR', axis=1)\n",
    "    df = df.drop('dust_pm1', axis = 1)\n",
    "    df = df.drop('dust_pm_25', axis = 1)\n",
    "    df = df.drop('dust_pm_10', axis = 1)\n",
    "    df_33 = df.values.reshape(-1,2,3)\n",
    "    return df_33, label\n",
    "\n",
    "#0~255 스케일링 함수\n",
    "def scale_255(array,i,j):\n",
    "    # i,j 위치의 요소들을 추출하여 배열 생성\n",
    "    first_elements = array[:, i, j]\n",
    "    # 첫 번째 요소들의 최솟값과 최댓값 계산\n",
    "    min_value = np.min(first_elements)\n",
    "    max_value = np.max(first_elements)\n",
    "    # 스케일링 수행\n",
    "    scaled_array = (first_elements - min_value) * (255 / (max_value - min_value))\n",
    "    return scaled_array\n",
    "\n",
    "def make_28(df_33):\n",
    "    # 결과 행렬을 저장할 빈 배열 생성\n",
    "    expanded_data = np.zeros((len(df_33), 28, 28))\n",
    "    # df_33의 각 3x3 배열에 대해 반복\n",
    "    for idx, arr in enumerate(df_33):\n",
    "        expanded_arr = np.repeat(arr,14,axis=0)\n",
    "        expanded_arr = np.repeat(expanded_arr,9,axis=1)\n",
    "        # 패딩을 추가한 새로운 28x28 배열 생성\n",
    "        expanded_arr = np.pad(expanded_arr, ((0, 1), (0, 1)), mode='constant')\n",
    "        expanded_data[idx] = expanded_arr\n",
    "    return expanded_data\n",
    "\n",
    "df = pd.read_csv(\"/Users/dongh/competition DATA/modified_train_data.csv\", encoding='ISO-8859-1')\n",
    "df_33, label = pre_df(df)\n",
    "#스케일링 함수 전체 적용\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        df_33[:,i,j] = scale_255(df_33,i,j)\n",
    "        \n",
    "df_33 = make_28(df_33)\n",
    "# 배열을 PyTorch Tensor로 변환\n",
    "input_data = torch.from_numpy(df_33).unsqueeze(1).float()  # 차원 수정\n",
    "# 라벨 데이터를 PyTorch Tensor로 변환\n",
    "target = torch.tensor(label.values)\n",
    "print(input_data.shape)\n",
    "#test\n",
    "df_test = pd.read_csv(\"/Users/dongh/competition DATA/modified_test_data.csv\", encoding='ISO-8859-1')\n",
    "df_test_33, label_test = pre_df(df_test)\n",
    "\n",
    "#스케일링 함수 전체 적용\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        df_test_33[:,i,j] = scale_255(df_test_33,i,j)\n",
    "        \n",
    "df_test_33 = make_28(df_test_33)\n",
    "# 배열을 PyTorch Tensor로 변환\n",
    "input_test = torch.from_numpy(df_test_33).unsqueeze(1).float()  # 차원 수정\n",
    "# 라벨 데이터를 PyTorch Tensor로 변환\n",
    "target_test = torch.tensor(label_test.values)\n",
    "print(input_test.shape)\n",
    "\n",
    "# LeNet-5 모델 정의 (시퀀셜)\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 5 * 5, 400),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(400, 120),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(120, 7)\n",
    ")\n",
    "\n",
    "# 모델 학습 또는 예측 수행\n",
    "\n",
    "# 손실 함수와 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 학습\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    # 입력 데이터의 forward pass\n",
    "    outputs = model(input_data)\n",
    "\n",
    "    # 손실 계산\n",
    "    loss = criterion(outputs, target)\n",
    "\n",
    "    # 역전파 및 가중치 업데이트\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 예측\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_test)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    # 예측 결과와 실제 라벨 비교하여 정확도 계산\n",
    "    accuracy = (predicted == target_test).sum().item() / target_test.size(0)\n",
    "\n",
    "    # 현재 에폭의 손실과 정확도 출력\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}, Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778aefbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
